{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial random forest predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hits_train = pd.read_csv( \"../train.csv\", index_col = 'global_id' )\n",
    "hits_test = pd.read_csv( \"../test.csv\", index_col = 'global_id' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wires = pd.read_csv(\"../wires.csv\", index_col='wire_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried another features: mean and std of energy for event, share of 15 neigbors with non-zero energy, average non-zero energy of 15 neighbors, but they didn't work for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = [\n",
    "    'energy_deposit', 'relative_time', 'log_en', 'sq_time',\n",
    "    'wire_x', 'wire_y', 'wire_r', 'x+y', 'x-y', 'x*y', ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We performed an extensive manual grid search of RF parameters, and found the default ones are best, dependence of the performance on number of estimators was looking like sqrt(x), so we decided to STACK MORE ESTIMATORS. It took about 30 minutes to fit and about 3 GB of swap in addition to 4 GB RAM (htop told that python swallowed 18GB of virtual memory). We were lucky to have fast SSD drive on one of the laptops to make it possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = ensemble.RandomForestClassifier( n_estimators = 10, criterion = 'gini',\n",
    "                                       max_depth = None, n_jobs = -1, verbose = 0, random_state = 13,\n",
    "                                       min_weight_fraction_leaf = 0.0, class_weight = None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_features( df, wires_df ) :\n",
    "    rho = wires_df[ 'wire_rho' ].values[ df.wire_id, np.newaxis ]\n",
    "    phi = wires_df[ 'wire_phi' ].values[ df.wire_id, np.newaxis ]\n",
    "    xy = np.concatenate( [ np.cos( phi ), np.sin( phi ) ], axis = 1 ) * rho\n",
    "    return pd.DataFrame( {\n",
    "## Basic coordinates\n",
    "        'wire_x' : xy[:,0], 'wire_y' : xy[:,1], 'wire_r' : rho[:,0],\n",
    "## Interactions\n",
    "        'x+y' : xy[:,0]+xy[:,1], 'x-y' : xy[:,0]-xy[:,1], 'x*y' : xy[:,0]*xy[:,1],\n",
    "## Physical features\n",
    "        'log_en' : np.log( df[ 'energy_deposit' ].values ** 2 ),\n",
    "        'sq_time' : df[ 'relative_time' ].values ** 2\n",
    "    }, index = df.index )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hits_train = pd.concat( [ hits_train, prepare_features( hits_train, wires ) ], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hits_test = pd.concat( [ hits_test, prepare_features( hits_test, wires ) ], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good = hits_train[ hits_train.energy_deposit > 0 ]\n",
    "clf.fit( good[ features_list ].values, ( good.label == 1 ).astype( np.int ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidates = hits_test[ hits_test.energy_deposit > 0 ]\n",
    "candidates.loc[:, 'prediction' ] = clf.predict_proba( candidates[ features_list ] )[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter predictions by the circle center +/- pi/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It goes through each event by id, plots histogram of the predictions and finds it's maximum based on the assumption that it should be around the center of the track circle.\n",
    "Overal it takes about 2-3 minutes to calculate everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for e in np.unique(candidates.event_id):\n",
    "    ev = candidates[candidates.event_id == e]\n",
    "    a,b=np.histogram(wires.values[ev[ev.prediction > .5].wire_id][:,1], \n",
    "                     weights=np.array(ev[ev.prediction > .5].prediction), bins=30)\n",
    "    # Find the maximum of the histogram and create bounds around it\n",
    "    mn = b[np.argmax(a)+1]\n",
    "    bounds = np.array([mn+(np.pi/2.),mn-(np.pi/2.)])\n",
    "    bounds = [bounds-(2*np.pi), bounds, bounds+(2*np.pi)]\n",
    "    # Complicated conditions, because phi lied within [0, 2pi] but there could\n",
    "    # be problems at the edges of the range.\n",
    "    cond = (wires.values[ev.wire_id][:,1] >= bounds[1][1])*(wires.values[ev.wire_id][:,1] <= bounds[1][0]) + \\\n",
    "           (wires.values[ev.wire_id][:,1] >= bounds[0][1])*(wires.values[ev.wire_id][:,1] <= bounds[0][0]) + \\\n",
    "           (wires.values[ev.wire_id][:,1] >= bounds[2][1])*(wires.values[ev.wire_id][:,1] <= bounds[2][0])\n",
    "    # Set everything outside the bounds to 0\n",
    "    candidates.loc[ev.index[-cond], 'prediction'] = np.zeros(np.sum(-cond))\n",
    "    print \"\\r\", e, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prs = pd.DataFrame({ 'prediction' : candidates.prediction }, index = candidates.index )\n",
    "prs.to_csv('../rf_with_filter_700.csv', index_label='global_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the rest by the window around the track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preds = pd.read_csv('../rf_with_filter_700.csv', index_col='global_id')\n",
    "# hits_test = pd.read_csv(\"data/nonzero_test_xyrphi.csv\", index_col='global_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hits_test =  pd.concat([hits_test, preds], axis=1)\n",
    "hits_test_fixed = hits_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hits_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing event to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_id = 1700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ev = hits_test[hits_test.event_id == check_id]\n",
    "\n",
    "vals = np.unique(ev.prediction)\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "a = np.histogram(ev.wire_x[ev.prediction > 0.5].values, bins=20)\n",
    "b = np.histogram(ev.wire_y[ev.prediction > 0.5].values, bins=20)\n",
    "\n",
    "x_mean = a[1][np.argmax(a[0])]\n",
    "y_mean = b[1][np.argmax(b[0])]\n",
    "\n",
    "for pr in vals:\n",
    "    plt.plot([ev.loc[i,'wire_x'] for i in ev[ev.prediction==pr].index], \n",
    "             [ev.loc[i,'wire_y'] for i in ev[ev.prediction==pr].index], 'k.', alpha = pr)\n",
    "    \n",
    "circ = plt.Circle((25,53), radius=19, color='r', linestyle='dashed', alpha=0.5, fill=False)\n",
    "ax.add_patch(circ)\n",
    "ax.text(-5, 74, r'Noise left after angle filtration', fontsize=15)\n",
    "plt.plot(x_mean, y_mean, 'ro', label='Center of x and y histograms')\n",
    "plt.legend(numpoints=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing denoise by x-y in cycle\n",
    "\n",
    "Condition is pretty straightforward: remove all the predictions outside 160x160 square with center in the red dot. A bit of overkill, but we needed to be sure that we wouldn't kill any signal points. There also was a try to perform filtering by radius (commented below), which didn't work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for e in np.unique(hits_test.event_id):\n",
    "    ev = hits_test[hits_test.event_id == e]\n",
    "    a = np.histogram(ev.wire_x[ev.prediction > 0.5].values, bins=20)\n",
    "    #a_weighted = np.histogram(ev.wire_x[ev.prediction > 0.5].values, bins=20, weights=ev.prediction[ev.prediction>0.5])\n",
    "    x_mean = a[1][np.argmax(a[0])]\n",
    "    bounds_x = np.array([x_mean-80, x_mean+80])\n",
    "    cond_x = (ev.wire_x > bounds_x[0])*(ev.wire_x < bounds_x[1])\n",
    "       \n",
    "    b = np.histogram(ev.wire_y[ev.prediction > 0.5].values, bins= 20, normed=True)\n",
    "    y_mean = b[1][np.argmax(b[0])]\n",
    "    bounds_y = np.array([y_mean-80, y_mean+80])\n",
    "    cond_y = (ev.wire_y > bounds_y[0])*(ev.wire_y < bounds_y[1])\n",
    "    \n",
    "    #there also was a try to perform filtering by radius\n",
    "    #ar = np.histogram(ev_fixed.wire_rho.values, bins=40, weights=ev_fixed.prediction.values)\n",
    "    #r_mean = ar[1][np.argmax(ar[0])]\n",
    "    #cond_r = ev.wire_rho > r_mean+5\n",
    "    \n",
    "    hits_test_fixed.loc[ev.index[-cond_x], 'prediction'] = np.zeros(np.sum(-cond_x))\n",
    "    hits_test_fixed.loc[ev.index[-cond_y], 'prediction'] = np.zeros(np.sum(-cond_y))\n",
    "    #hits_test_fixed.loc[ev.index[-cond_r], 'prediction'] = np.zeros(np.sum(-cond_r))\n",
    "    \n",
    "    #print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ev_fixed = hits_test_fixed[hits_test.event_id == check_id]\n",
    "vals_fixed = np.unique(ev_fixed.prediction)\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "a = np.histogram(ev_fixed[ev_fixed.prediction > 0.5].wire_rho.values, bins=40, weights=ev_fixed[ev_fixed.prediction > 0.5].prediction.values)\n",
    "\n",
    "\n",
    "maxr = a[1][np.argmax(a[0])]\n",
    "\n",
    "for pr in vals_fixed:\n",
    "    plt.plot([ev_fixed.loc[i,'wire_x'] for i in ev_fixed[ev_fixed.prediction==pr].index], \n",
    "             [ev_fixed.loc[i,'wire_y'] for i in ev_fixed[ev_fixed.prediction==pr].index], 'k.', alpha = pr)\n",
    "    \n",
    "circ = plt.Circle((25,53), radius=19, color='r', linestyle='dashed', alpha=0.5, fill=False)\n",
    "ax.add_patch(circ)\n",
    "ax.text(3, 74, r'Now noise is gone!', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking predictions distribution for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(hits_test_fixed.prediction.values, bins = 100)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving predictions for submit and hoping for the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prs = pd.DataFrame()\n",
    "prs['prediction'] = hits_test_fixed.prediction\n",
    "prs.index = hits_test_fixed.index\n",
    "prs.to_csv('rf_manlike_and_filter_700_xy_denoise.csv', index_label='global_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
